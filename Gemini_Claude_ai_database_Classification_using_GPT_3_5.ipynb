{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYeIOtsdQLKXTbgv4yY0cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kandi00/Objectivity-detection/blob/main/Gemini_Claude_ai_database_Classification_using_GPT_3_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIhFwUPH_LEc",
        "outputId": "0317498a-ca1c-4546-997c-d74137cd674c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "bLScJiEMqubl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "69Avi8GY-BU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# account for deprecation of LLM model\n",
        "import datetime\n",
        "# Get the current date\n",
        "current_date = datetime.datetime.now().date()\n",
        "\n",
        "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
        "target_date = datetime.date(2024, 6, 12)\n",
        "\n",
        "# Set the model variable based on the current date\n",
        "# if current_date > target_date:\n",
        "llm_model = \"gpt-3.5-turbo\"\n",
        "# else:\n",
        "#     llm_model = \"gpt-3.5-turbo-0301\""
      ],
      "metadata": {
        "id": "tNo1cOCgq0fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=llm_model):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "CDdrXk7RHLnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ls = []\n",
        "file_path = \"/content/drive/My Drive/Disszertacio/gemini_test.tsv\"\n",
        "# file_path = \"/content/drive/My Drive/Disszertacio/Claude_ai_test.tsv\"\n",
        "test_data = pd.read_csv(file_path, delimiter='\\t')\n",
        "print(test_data)\n",
        "\n",
        "text_column = test_data.iloc[:, 0]\n",
        "\n",
        "for message in text_column:\n",
        "  prompt = f\"\"\"\n",
        "  Given the following sentence: {message}. You are an expert linguist and have to classify it as subjective or objective.\n",
        "  Something is subjective if it is dependent on a mind. Something is objective if it can be confirmed independently of a mind.\n",
        "  Your response should only contain one word\"\"\"\n",
        "  ls.append(get_completion(prompt))\n",
        "  # time.sleep(0.5)"
      ],
      "metadata": {
        "id": "HsZUVQyq-Ck8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b952520-77b1-489d-e952-ded87de2a923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  text  label\n",
            "0    The protagonist's journey in this book feels i...      1\n",
            "1    The way the sunlight filters through the leave...      1\n",
            "2    This documentary changed my perspective on a c...      1\n",
            "3    The ending of that movie left me feeling utter...      1\n",
            "4    The vibrant colors in this painting evoke a se...      1\n",
            "..                                                 ...    ...\n",
            "195  The painting is a symbolic representation of a...      0\n",
            "196  The building is undergoing renovations to mode...      0\n",
            "197  The recipe is a vegetarian option that is stil...      0\n",
            "198  This building serves as a public library and o...      0\n",
            "199  The population of this country is aging rapidl...      0\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah90Twh3SC4v",
        "outputId": "79ed858f-0f62-45c5-8552-b1a02271da28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Subjective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ls))\n",
        "predicted_text_lables = [item.replace('\\n', '').replace('.', '') for item in ls]\n",
        "print(predicted_text_lables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIB66dxWSEB-",
        "outputId": "4cb155a1-2158-4516-b76d-add8a1f1da3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "['Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Subjective', 'Subjective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Objective', 'Subjective', 'Objective', 'Objective']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels = [1] * 100 + [0] * 100"
      ],
      "metadata": {
        "id": "3Bdawrb1f94U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'subjective': 1, 'objective': 0, 'subject': 1, 'object': 0, 'Subjective' : 1, 'Objective' : 0, 'Subject' : 1}\n",
        "# Convert labels to binary values\n",
        "predicted_labels = [label_map[label] for label in predicted_text_lables]\n",
        "\n",
        "print(valid_labels)\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJcef9XEFd6D",
        "outputId": "3b8e4bee-f849-45fc-9cf1-39f0ffeb61cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(valid_labels, predicted_labels):\n",
        "    # Calculate accuracy\n",
        "    accuracy = sum(1 for v, p in zip(valid_labels, predicted_labels) if v == p) / len(valid_labels)\n",
        "\n",
        "    # Calculate true positives, false positives, and false negatives\n",
        "    true_positives = sum(1 for v, p in zip(valid_labels, predicted_labels) if v == p and v == 1)\n",
        "    true_negatives = sum(1 for v, p in zip(valid_labels, predicted_labels) if v == p and v == 0)\n",
        "    false_positives = sum(1 for v, p in zip(valid_labels, predicted_labels) if v != p and p == 1)\n",
        "    false_negatives = sum(1 for v, p in zip(valid_labels, predicted_labels) if v != p and v == 1)\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return accuracy, precision, recall, f1_score, true_positives, false_positives, false_negatives, true_negatives\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy, precision, recall, f1_score, true_positives, false_positives, false_negatives, true_negatives = calculate_metrics(valid_labels, predicted_labels)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"false_positives:\", false_positives)\n",
        "print(\"false_negatives:\", false_negatives)\n",
        "print(\"true_positives:\", true_positives)\n",
        "print(\"true_negatives:\", true_negatives)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppOxcjhZFrnS",
        "outputId": "f5a47cb3-2250-4b35-a45d-a7e9a30779e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n",
            "Precision: 0.9259259259259259\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9615384615384615\n",
            "false_positives: 8\n",
            "false_negatives: 0\n",
            "true_positives: 100\n",
            "true_negatives: 92\n"
          ]
        }
      ]
    }
  ]
}